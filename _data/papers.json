[
  {
    "title": "Literature Review of Mixed Reality Research",
    "authors": [
      "Aiersilan, Aizierjiang"
    ],
    "date": "2023-12-15",
    "abstract": "In the global context, while mixed reality has been an emerging concept for years, recent technological and scientific advancements have now made it poised to revolutionize industries and daily life by offering enhanced functionalities and improved services. Besides reviewing the highly cited papers in the last 20 years among over a thousand research papers on mixed reality, this systematic review provides the state-of-the-art applications and utilities of the mixed reality by primarily scrutinizing the associated papers in 2022 and 2023. Focusing on the potentials that this technology have in providing digitally supported simulations and other utilities in the era of large language models, highlighting the potential and limitations of the innovative solutions and also bringing focus to emerging research directions, such as telemedicine, remote control and optimization of direct volume rendering. The paper's associated repository is publicly accessible at https://aizierjiang.github.io/mr.",
    "pdf": "LiteratureReviewofMixedRealityResearch.pdf",
    "venue": "2023 2nd International Conference on Educational Science and Social Culture (ESSC 2023)"
  },
  {
    "title": "A 3D Framework for Improving Low-Latency Multi-Channel Live Streaming",
    "authors": [
      "Aiersilan, Aizierjiang and Zhiqiang Wang"
    ],
    "date": "2025-6-15",
    "abstract": "The advent of 5G has driven the demand for high-quality, low-latency live streaming. However, challenges such as managing the increased data volume, ensuring synchronization across multiple streams, and maintaining consistent quality under varying network conditions persist, particularly in real-time video streaming. To address these issues, we propose a novel framework that leverages 3D virtual environments within game engines(e.g., Unity 3D) to optimize multi-channel live streaming. Our approach consolidates multi-camera video data into a single stream using multiple virtual 3D canvases, significantly increasing channel amounts while reducing latency and enhancing user flexibility. For demonstration of our approach, we utilize theUnity 3D engine to integrate multiple video inputs into a single-channel stream, supporting one-to-many broadcasting, one-to-one video calling, and real-time control of video channels. By mapping video data onto a world-space canvas and capturing it via an in-world camera, we minimize redundant data trans-mission, achieving efficient, low-latency streaming. Our results demonstrate that this method outperforms some existing multi-channel live streaming solutions in both latency reduction and user interaction responsiveness improvement.",
    "pdf": "A3DFrameworkforImprovingLowLatencyMultiChannelLiveStreaming.pdf",
    "venue": "2025 IEEE International Conference on Multimedia and Expo Workshops (ICMEW 2025)"
  }
]